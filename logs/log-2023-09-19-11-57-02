09/19/2023 11:57:02 - INFO - pytorch_pretrained_zen.modeling -   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
09/19/2023 11:57:02 - INFO - __main__ -   {'do_train': True, 'do_test': False, 'do_predict': False, 'do_predict_uc': False, 'train_data_path': './data/mydata/larger/train.tsv', 'self_train_data_path': '/opt/Projects/Python/WMSeg/data_preprocessing/mydata/larger/self_train.tsv', 'eval_data_path': './data/mydata/larger/test.tsv', 'input_file': None, 'output_file': None, 'output_file_tsv': None, 'use_bert': True, 'use_zen': False, 'bert_model': '/opt/Projects/Python/WMSeg/models/Zen', 'eval_model': None, 'cache_dir': '', 'max_seq_length': 300, 'max_ngram_size': 300, 'do_lower_case': False, 'train_batch_size': 16, 'eval_batch_size': 16, 'lambda_rate': 0.3, 'learning_rate': 1e-05, 'num_train_epochs': 50.0, 'warmup_proportion': 0.1, 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'gradient_accumulation_steps': 1, 'fp16': False, 'loss_scale': 0, 'server_ip': '', 'server_port': '', 'patient': 10, 'ngram_num_threshold': 2, 'av_threshold': 3, 'max_ngram_length': 5, 'model_name': 'self_Zen_memory_crf', 'use_memory': True, 'use_cnn': False, 'decoder': 'crf', 'ngram_flag': 'av', 'save_top': 1}
09/19/2023 11:57:02 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
09/19/2023 11:57:02 - INFO - __main__ -   # of word in train: 1079: 
09/19/2023 11:57:03 - INFO - __main__ -   # of n-gram in memory: 1237
09/19/2023 11:57:03 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file /opt/Projects/Python/WMSeg/models/Zen/vocab.txt
09/19/2023 11:57:03 - INFO - pytorch_pretrained_bert.modeling -   loading weights file /opt/Projects/Python/WMSeg/models/Zen/pytorch_model.bin
09/19/2023 11:57:03 - INFO - pytorch_pretrained_bert.modeling -   loading configuration file /opt/Projects/Python/WMSeg/models/Zen/config.json
09/19/2023 11:57:03 - INFO - pytorch_pretrained_bert.modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_hidden_word_layers": 6,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128,
  "word_size": 104089
}

09/19/2023 11:57:03 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertModel: ['bert.word_embeddings.word_embeddings.weight', 'bert.word_embeddings.token_type_embeddings.weight', 'bert.word_embeddings.LayerNorm.weight', 'bert.word_embeddings.LayerNorm.bias', 'bert.encoder.word_layers.0.attention.self.query.weight', 'bert.encoder.word_layers.0.attention.self.query.bias', 'bert.encoder.word_layers.0.attention.self.key.weight', 'bert.encoder.word_layers.0.attention.self.key.bias', 'bert.encoder.word_layers.0.attention.self.value.weight', 'bert.encoder.word_layers.0.attention.self.value.bias', 'bert.encoder.word_layers.0.attention.output.dense.weight', 'bert.encoder.word_layers.0.attention.output.dense.bias', 'bert.encoder.word_layers.0.attention.output.LayerNorm.weight', 'bert.encoder.word_layers.0.attention.output.LayerNorm.bias', 'bert.encoder.word_layers.0.intermediate.dense.weight', 'bert.encoder.word_layers.0.intermediate.dense.bias', 'bert.encoder.word_layers.0.output.dense.weight', 'bert.encoder.word_layers.0.output.dense.bias', 'bert.encoder.word_layers.0.output.LayerNorm.weight', 'bert.encoder.word_layers.0.output.LayerNorm.bias', 'bert.encoder.word_layers.1.attention.self.query.weight', 'bert.encoder.word_layers.1.attention.self.query.bias', 'bert.encoder.word_layers.1.attention.self.key.weight', 'bert.encoder.word_layers.1.attention.self.key.bias', 'bert.encoder.word_layers.1.attention.self.value.weight', 'bert.encoder.word_layers.1.attention.self.value.bias', 'bert.encoder.word_layers.1.attention.output.dense.weight', 'bert.encoder.word_layers.1.attention.output.dense.bias', 'bert.encoder.word_layers.1.attention.output.LayerNorm.weight', 'bert.encoder.word_layers.1.attention.output.LayerNorm.bias', 'bert.encoder.word_layers.1.intermediate.dense.weight', 'bert.encoder.word_layers.1.intermediate.dense.bias', 'bert.encoder.word_layers.1.output.dense.weight', 'bert.encoder.word_layers.1.output.dense.bias', 'bert.encoder.word_layers.1.output.LayerNorm.weight', 'bert.encoder.word_layers.1.output.LayerNorm.bias', 'bert.encoder.word_layers.2.attention.self.query.weight', 'bert.encoder.word_layers.2.attention.self.query.bias', 'bert.encoder.word_layers.2.attention.self.key.weight', 'bert.encoder.word_layers.2.attention.self.key.bias', 'bert.encoder.word_layers.2.attention.self.value.weight', 'bert.encoder.word_layers.2.attention.self.value.bias', 'bert.encoder.word_layers.2.attention.output.dense.weight', 'bert.encoder.word_layers.2.attention.output.dense.bias', 'bert.encoder.word_layers.2.attention.output.LayerNorm.weight', 'bert.encoder.word_layers.2.attention.output.LayerNorm.bias', 'bert.encoder.word_layers.2.intermediate.dense.weight', 'bert.encoder.word_layers.2.intermediate.dense.bias', 'bert.encoder.word_layers.2.output.dense.weight', 'bert.encoder.word_layers.2.output.dense.bias', 'bert.encoder.word_layers.2.output.LayerNorm.weight', 'bert.encoder.word_layers.2.output.LayerNorm.bias', 'bert.encoder.word_layers.3.attention.self.query.weight', 'bert.encoder.word_layers.3.attention.self.query.bias', 'bert.encoder.word_layers.3.attention.self.key.weight', 'bert.encoder.word_layers.3.attention.self.key.bias', 'bert.encoder.word_layers.3.attention.self.value.weight', 'bert.encoder.word_layers.3.attention.self.value.bias', 'bert.encoder.word_layers.3.attention.output.dense.weight', 'bert.encoder.word_layers.3.attention.output.dense.bias', 'bert.encoder.word_layers.3.attention.output.LayerNorm.weight', 'bert.encoder.word_layers.3.attention.output.LayerNorm.bias', 'bert.encoder.word_layers.3.intermediate.dense.weight', 'bert.encoder.word_layers.3.intermediate.dense.bias', 'bert.encoder.word_layers.3.output.dense.weight', 'bert.encoder.word_layers.3.output.dense.bias', 'bert.encoder.word_layers.3.output.LayerNorm.weight', 'bert.encoder.word_layers.3.output.LayerNorm.bias', 'bert.encoder.word_layers.4.attention.self.query.weight', 'bert.encoder.word_layers.4.attention.self.query.bias', 'bert.encoder.word_layers.4.attention.self.key.weight', 'bert.encoder.word_layers.4.attention.self.key.bias', 'bert.encoder.word_layers.4.attention.self.value.weight', 'bert.encoder.word_layers.4.attention.self.value.bias', 'bert.encoder.word_layers.4.attention.output.dense.weight', 'bert.encoder.word_layers.4.attention.output.dense.bias', 'bert.encoder.word_layers.4.attention.output.LayerNorm.weight', 'bert.encoder.word_layers.4.attention.output.LayerNorm.bias', 'bert.encoder.word_layers.4.intermediate.dense.weight', 'bert.encoder.word_layers.4.intermediate.dense.bias', 'bert.encoder.word_layers.4.output.dense.weight', 'bert.encoder.word_layers.4.output.dense.bias', 'bert.encoder.word_layers.4.output.LayerNorm.weight', 'bert.encoder.word_layers.4.output.LayerNorm.bias', 'bert.encoder.word_layers.5.attention.self.query.weight', 'bert.encoder.word_layers.5.attention.self.query.bias', 'bert.encoder.word_layers.5.attention.self.key.weight', 'bert.encoder.word_layers.5.attention.self.key.bias', 'bert.encoder.word_layers.5.attention.self.value.weight', 'bert.encoder.word_layers.5.attention.self.value.bias', 'bert.encoder.word_layers.5.attention.output.dense.weight', 'bert.encoder.word_layers.5.attention.output.dense.bias', 'bert.encoder.word_layers.5.attention.output.LayerNorm.weight', 'bert.encoder.word_layers.5.attention.output.LayerNorm.bias', 'bert.encoder.word_layers.5.intermediate.dense.weight', 'bert.encoder.word_layers.5.intermediate.dense.bias', 'bert.encoder.word_layers.5.output.dense.weight', 'bert.encoder.word_layers.5.output.dense.bias', 'bert.encoder.word_layers.5.output.LayerNorm.weight', 'bert.encoder.word_layers.5.output.LayerNorm.bias']
09/19/2023 11:57:04 - INFO - __main__ -   # of trainable parameters: 103231552
09/19/2023 11:57:04 - INFO - __main__ -   ***** Running self-training *****
09/19/2023 11:57:04 - INFO - __main__ -     Num examples = 120
09/19/2023 11:57:04 - INFO - __main__ -     Num self-train examples = 2
09/19/2023 11:57:04 - INFO - __main__ -     Batch size = 16
09/19/2023 11:57:04 - INFO - __main__ -     Num steps = 350
09/19/2023 11:57:10 - INFO - __main__ -   OOV: 0.043506
09/19/2023 11:57:10 - INFO - __main__ -   GEO: 0.008054
09/19/2023 11:57:10 - INFO - __main__ -   =======entity level========
09/19/2023 11:57:10 - INFO - __main__ -   
Epoch: 1, P: 0.165706, R: 0.132419, F: 0.147204, OOV: 0.043506, GEO: 0.008054
09/19/2023 11:57:10 - INFO - __main__ -   =======entity level========
09/19/2023 11:57:17 - INFO - __main__ -   OOV: 0.251440
09/19/2023 11:57:17 - INFO - __main__ -   GEO: 0.163758
09/19/2023 11:57:17 - INFO - __main__ -   =======entity level========
09/19/2023 11:57:17 - INFO - __main__ -   
Epoch: 2, P: 0.589904, R: 0.577137, F: 0.583451, OOV: 0.251440, GEO: 0.163758
09/19/2023 11:57:17 - INFO - __main__ -   =======entity level========
09/19/2023 11:57:25 - INFO - __main__ -   OOV: 0.614523
09/19/2023 11:57:25 - INFO - __main__ -   GEO: 0.512752
09/19/2023 11:57:25 - INFO - __main__ -   =======entity level========
09/19/2023 11:57:25 - INFO - __main__ -   
Epoch: 3, P: 0.800934, R: 0.789694, F: 0.795274, OOV: 0.614523, GEO: 0.512752
09/19/2023 11:57:25 - INFO - __main__ -   =======entity level========
09/19/2023 11:57:32 - INFO - __main__ -   OOV: 0.722649
09/19/2023 11:57:32 - INFO - __main__ -   GEO: 0.645638
09/19/2023 11:57:32 - INFO - __main__ -   =======entity level========
09/19/2023 11:57:32 - INFO - __main__ -   
Epoch: 4, P: 0.880495, R: 0.854082, F: 0.867087, OOV: 0.722649, GEO: 0.645638
09/19/2023 11:57:32 - INFO - __main__ -   =======entity level========
09/19/2023 11:57:39 - INFO - __main__ -   OOV: 0.758157
09/19/2023 11:57:39 - INFO - __main__ -   GEO: 0.700671
09/19/2023 11:57:39 - INFO - __main__ -   =======entity level========
09/19/2023 11:57:39 - INFO - __main__ -   
Epoch: 5, P: 0.870287, R: 0.887722, F: 0.878918, OOV: 0.758157, GEO: 0.700671
09/19/2023 11:57:39 - INFO - __main__ -   =======entity level========
09/19/2023 11:57:46 - INFO - __main__ -   OOV: 0.802303
09/19/2023 11:57:46 - INFO - __main__ -   GEO: 0.824161
09/19/2023 11:57:46 - INFO - __main__ -   =======entity level========
09/19/2023 11:57:46 - INFO - __main__ -   
Epoch: 6, P: 0.907762, R: 0.904650, F: 0.906203, OOV: 0.802303, GEO: 0.824161
09/19/2023 11:57:46 - INFO - __main__ -   =======entity level========
09/19/2023 11:57:53 - INFO - __main__ -   OOV: 0.798784
09/19/2023 11:57:53 - INFO - __main__ -   GEO: 0.761074
09/19/2023 11:57:53 - INFO - __main__ -   =======entity level========
09/19/2023 11:57:53 - INFO - __main__ -   
Epoch: 7, P: 0.900932, R: 0.910971, F: 0.905924, OOV: 0.798784, GEO: 0.761074
09/19/2023 11:57:53 - INFO - __main__ -   =======entity level========
09/19/2023 11:58:00 - INFO - __main__ -   OOV: 0.804862
09/19/2023 11:58:00 - INFO - __main__ -   GEO: 0.845638
09/19/2023 11:58:00 - INFO - __main__ -   =======entity level========
09/19/2023 11:58:00 - INFO - __main__ -   
Epoch: 8, P: 0.929591, R: 0.899614, F: 0.914357, OOV: 0.804862, GEO: 0.845638
09/19/2023 11:58:00 - INFO - __main__ -   =======entity level========
09/19/2023 11:58:07 - INFO - __main__ -   OOV: 0.809341
09/19/2023 11:58:07 - INFO - __main__ -   GEO: 0.814765
09/19/2023 11:58:07 - INFO - __main__ -   =======entity level========
09/19/2023 11:58:07 - INFO - __main__ -   
Epoch: 9, P: 0.920557, R: 0.906257, F: 0.913351, OOV: 0.809341, GEO: 0.814765
09/19/2023 11:58:07 - INFO - __main__ -   =======entity level========
09/19/2023 11:58:14 - INFO - __main__ -   OOV: 0.804862
09/19/2023 11:58:14 - INFO - __main__ -   GEO: 0.864430
09/19/2023 11:58:14 - INFO - __main__ -   =======entity level========
09/19/2023 11:58:14 - INFO - __main__ -   
Epoch: 10, P: 0.928311, R: 0.900364, F: 0.914124, OOV: 0.804862, GEO: 0.864430
09/19/2023 11:58:14 - INFO - __main__ -   =======entity level========
09/19/2023 11:58:21 - INFO - __main__ -   OOV: 0.799744
09/19/2023 11:58:21 - INFO - __main__ -   GEO: 0.775839
09/19/2023 11:58:21 - INFO - __main__ -   =======entity level========
09/19/2023 11:58:21 - INFO - __main__ -   
Epoch: 11, P: 0.907836, R: 0.908614, F: 0.908224, OOV: 0.799744, GEO: 0.775839
09/19/2023 11:58:21 - INFO - __main__ -   =======entity level========
09/19/2023 11:58:28 - INFO - __main__ -   OOV: 0.819578
09/19/2023 11:58:28 - INFO - __main__ -   GEO: 0.863087
09/19/2023 11:58:28 - INFO - __main__ -   =======entity level========
09/19/2023 11:58:28 - INFO - __main__ -   
Epoch: 12, P: 0.930475, R: 0.909042, F: 0.919634, OOV: 0.819578, GEO: 0.863087
09/19/2023 11:58:28 - INFO - __main__ -   =======entity level========
09/19/2023 11:58:34 - INFO - __main__ -   OOV: 0.817658
09/19/2023 11:58:34 - INFO - __main__ -   GEO: 0.851007
09/19/2023 11:58:34 - INFO - __main__ -   =======entity level========
09/19/2023 11:58:34 - INFO - __main__ -   
Epoch: 13, P: 0.922476, R: 0.910221, F: 0.916307, OOV: 0.817658, GEO: 0.851007
09/19/2023 11:58:34 - INFO - __main__ -   =======entity level========
09/19/2023 11:58:41 - INFO - __main__ -   OOV: 0.821177
09/19/2023 11:58:41 - INFO - __main__ -   GEO: 0.852349
09/19/2023 11:58:41 - INFO - __main__ -   =======entity level========
09/19/2023 11:58:41 - INFO - __main__ -   
Epoch: 14, P: 0.927738, R: 0.911935, F: 0.919769, OOV: 0.821177, GEO: 0.852349
09/19/2023 11:58:41 - INFO - __main__ -   =======entity level========
09/19/2023 11:58:47 - INFO - __main__ -   OOV: 0.815739
09/19/2023 11:58:47 - INFO - __main__ -   GEO: 0.855034
09/19/2023 11:58:47 - INFO - __main__ -   =======entity level========
09/19/2023 11:58:47 - INFO - __main__ -   
Epoch: 15, P: 0.928228, R: 0.908935, F: 0.918480, OOV: 0.815739, GEO: 0.855034
09/19/2023 11:58:47 - INFO - __main__ -   =======entity level========
09/19/2023 11:58:54 - INFO - __main__ -   OOV: 0.815099
09/19/2023 11:58:54 - INFO - __main__ -   GEO: 0.883221
09/19/2023 11:58:54 - INFO - __main__ -   =======entity level========
09/19/2023 11:58:54 - INFO - __main__ -   
Epoch: 16, P: 0.931951, R: 0.905292, F: 0.918428, OOV: 0.815099, GEO: 0.883221
09/19/2023 11:58:54 - INFO - __main__ -   =======entity level========
09/19/2023 11:59:01 - INFO - __main__ -   OOV: 0.811900
09/19/2023 11:59:01 - INFO - __main__ -   GEO: 0.861745
09/19/2023 11:59:01 - INFO - __main__ -   =======entity level========
09/19/2023 11:59:01 - INFO - __main__ -   
Epoch: 17, P: 0.921934, R: 0.910971, F: 0.916420, OOV: 0.811900, GEO: 0.861745
09/19/2023 11:59:01 - INFO - __main__ -   =======entity level========
09/19/2023 11:59:08 - INFO - __main__ -   OOV: 0.819578
09/19/2023 11:59:08 - INFO - __main__ -   GEO: 0.851007
09/19/2023 11:59:08 - INFO - __main__ -   =======entity level========
09/19/2023 11:59:08 - INFO - __main__ -   
Epoch: 18, P: 0.920544, R: 0.913542, F: 0.917030, OOV: 0.819578, GEO: 0.851007
09/19/2023 11:59:08 - INFO - __main__ -   =======entity level========
09/19/2023 11:59:14 - INFO - __main__ -   OOV: 0.807422
09/19/2023 11:59:14 - INFO - __main__ -   GEO: 0.877852
09/19/2023 11:59:14 - INFO - __main__ -   =======entity level========
09/19/2023 11:59:14 - INFO - __main__ -   
Epoch: 19, P: 0.923549, R: 0.902078, F: 0.912688, OOV: 0.807422, GEO: 0.877852
09/19/2023 11:59:14 - INFO - __main__ -   =======entity level========
09/19/2023 11:59:21 - INFO - __main__ -   OOV: 0.812220
09/19/2023 11:59:21 - INFO - __main__ -   GEO: 0.853691
09/19/2023 11:59:21 - INFO - __main__ -   =======entity level========
09/19/2023 11:59:21 - INFO - __main__ -   
Epoch: 20, P: 0.916828, R: 0.910542, F: 0.913674, OOV: 0.812220, GEO: 0.853691
09/19/2023 11:59:21 - INFO - __main__ -   =======entity level========
09/19/2023 11:59:27 - INFO - __main__ -   OOV: 0.816699
09/19/2023 11:59:27 - INFO - __main__ -   GEO: 0.863087
09/19/2023 11:59:27 - INFO - __main__ -   =======entity level========
09/19/2023 11:59:27 - INFO - __main__ -   
Epoch: 21, P: 0.928118, R: 0.908828, F: 0.918372, OOV: 0.816699, GEO: 0.863087
09/19/2023 11:59:27 - INFO - __main__ -   =======entity level========
09/19/2023 11:59:34 - INFO - __main__ -   OOV: 0.820218
09/19/2023 11:59:34 - INFO - __main__ -   GEO: 0.859060
09/19/2023 11:59:34 - INFO - __main__ -   =======entity level========
09/19/2023 11:59:34 - INFO - __main__ -   
Epoch: 22, P: 0.927815, R: 0.910221, F: 0.918934, OOV: 0.820218, GEO: 0.859060
09/19/2023 11:59:34 - INFO - __main__ -   =======entity level========
09/19/2023 11:59:40 - INFO - __main__ -   OOV: 0.817019
09/19/2023 11:59:40 - INFO - __main__ -   GEO: 0.857718
09/19/2023 11:59:40 - INFO - __main__ -   =======entity level========
09/19/2023 11:59:40 - INFO - __main__ -   
Epoch: 23, P: 0.929940, R: 0.910114, F: 0.919920, OOV: 0.817019, GEO: 0.857718
09/19/2023 11:59:40 - INFO - __main__ -   =======entity level========

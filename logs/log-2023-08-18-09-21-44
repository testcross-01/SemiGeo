08/18/2023 09:21:44 - INFO - pytorch_pretrained_zen.modeling -   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .
08/18/2023 09:21:44 - INFO - __main__ -   {'do_train': True, 'do_test': False, 'do_predict': False, 'train_data_path': './data/mydata/large/train.tsv', 'self_train_data_path': './data_preprocessing/mydata/large/self_train.tsv', 'eval_data_path': './data/mydata/large/test.tsv', 'input_file': None, 'output_file': None, 'output_file_tsv': None, 'use_bert': False, 'use_zen': True, 'bert_model': '/opt/Projects/Python/WMSeg/models/Zen', 'eval_model': None, 'cache_dir': '', 'max_seq_length': 300, 'max_ngram_size': 300, 'do_lower_case': False, 'train_batch_size': 16, 'eval_batch_size': 16, 'lambda_rate': 0.5, 'learning_rate': 1e-05, 'num_train_epochs': 50.0, 'warmup_proportion': 0.1, 'no_cuda': False, 'local_rank': -1, 'seed': 42, 'gradient_accumulation_steps': 1, 'fp16': False, 'loss_scale': 0, 'server_ip': '', 'server_port': '', 'patient': 10, 'ngram_num_threshold': 2, 'av_threshold': 3, 'max_ngram_length': 5, 'model_name': 'self_Zen_memory_crf', 'use_memory': True, 'use_gcn': False, 'decoder': 'crf', 'ngram_flag': 'av', 'save_top': 1}
08/18/2023 09:21:44 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
08/18/2023 09:21:44 - INFO - __main__ -   # of word in train: 1087: 
08/18/2023 09:21:44 - INFO - __main__ -   # of n-gram in memory: 502
08/18/2023 09:21:44 - INFO - pytorch_pretrained_zen.tokenization -   loading vocabulary file /opt/Projects/Python/WMSeg/models/Zen/vocab.txt
08/18/2023 09:21:44 - INFO - pytorch_pretrained_zen.ngram_utils -   loading ngram frequency file /opt/Projects/Python/WMSeg/models/Zen/ngram.txt
08/18/2023 09:21:45 - INFO - pytorch_pretrained_zen.modeling -   loading weights file /opt/Projects/Python/WMSeg/models/Zen/pytorch_model.bin
08/18/2023 09:21:45 - INFO - pytorch_pretrained_zen.modeling -   loading configuration file /opt/Projects/Python/WMSeg/models/Zen/config.json
08/18/2023 09:21:45 - INFO - pytorch_pretrained_zen.modeling -   Model config {
  "attention_probs_dropout_prob": 0.1,
  "directionality": "bidi",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_hidden_word_layers": 6,
  "pooler_fc_size": 768,
  "pooler_num_attention_heads": 12,
  "pooler_num_fc_layers": 3,
  "pooler_size_per_head": 128,
  "pooler_type": "first_token_transform",
  "type_vocab_size": 2,
  "vocab_size": 21128,
  "word_size": 104089
}

08/18/2023 09:21:47 - INFO - __main__ -   # of trainable parameters: 225137728
08/18/2023 09:21:47 - INFO - __main__ -   ***** Running self-training *****
08/18/2023 09:21:47 - INFO - __main__ -     Num examples = 137
08/18/2023 09:21:47 - INFO - __main__ -     Num self-train examples = 145
08/18/2023 09:21:47 - INFO - __main__ -     Batch size = 16
08/18/2023 09:21:47 - INFO - __main__ -     Num steps = 850
08/18/2023 09:21:48 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:21:49 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:21:50 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:21:51 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:21:52 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:21:53 - INFO - __main__ -    self-train batch num in this step = 2
08/18/2023 09:21:54 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:21:56 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:21:57 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:21:58 - INFO - __main__ -   OOV: 0.125182
08/18/2023 09:21:58 - INFO - __main__ -   =======entity level========
08/18/2023 09:21:58 - INFO - __main__ -   
Epoch: 1, P: 0.488718, R: 0.349331, F: 0.407433, OOV: 0.125182
08/18/2023 09:21:58 - INFO - __main__ -   =======entity level========
08/18/2023 09:22:04 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:05 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:06 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:07 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:08 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:09 - INFO - __main__ -    self-train batch num in this step = 2
08/18/2023 09:22:10 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:11 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:12 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:14 - INFO - __main__ -   OOV: 0.612809
08/18/2023 09:22:14 - INFO - __main__ -   =======entity level========
08/18/2023 09:22:14 - INFO - __main__ -   
Epoch: 2, P: 0.817331, R: 0.790323, F: 0.803600, OOV: 0.612809
08/18/2023 09:22:14 - INFO - __main__ -   =======entity level========
08/18/2023 09:22:19 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:20 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:21 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:22 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:23 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:25 - INFO - __main__ -    self-train batch num in this step = 2
08/18/2023 09:22:26 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:27 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:28 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:29 - INFO - __main__ -   OOV: 0.778748
08/18/2023 09:22:29 - INFO - __main__ -   =======entity level========
08/18/2023 09:22:29 - INFO - __main__ -   
Epoch: 3, P: 0.903174, R: 0.884343, F: 0.893659, OOV: 0.778748
08/18/2023 09:22:29 - INFO - __main__ -   =======entity level========
08/18/2023 09:22:34 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:35 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:36 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:37 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:38 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:39 - INFO - __main__ -    self-train batch num in this step = 2
08/18/2023 09:22:40 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:41 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:42 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:44 - INFO - __main__ -   OOV: 0.784571
08/18/2023 09:22:44 - INFO - __main__ -   =======entity level========
08/18/2023 09:22:44 - INFO - __main__ -   
Epoch: 4, P: 0.919806, R: 0.893391, F: 0.906406, OOV: 0.784571
08/18/2023 09:22:44 - INFO - __main__ -   =======entity level========
08/18/2023 09:22:49 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:50 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:51 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:52 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:53 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:54 - INFO - __main__ -    self-train batch num in this step = 2
08/18/2023 09:22:55 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:56 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:57 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:22:58 - INFO - __main__ -   OOV: 0.797671
08/18/2023 09:22:58 - INFO - __main__ -   =======entity level========
08/18/2023 09:22:58 - INFO - __main__ -   
Epoch: 5, P: 0.924414, R: 0.899685, F: 0.911882, OOV: 0.797671
08/18/2023 09:22:58 - INFO - __main__ -   =======entity level========
08/18/2023 09:23:03 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:23:04 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:23:05 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:23:06 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:23:07 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:23:09 - INFO - __main__ -    self-train batch num in this step = 2
08/18/2023 09:23:10 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:23:11 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:23:12 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:23:13 - INFO - __main__ -   OOV: 0.797671
08/18/2023 09:23:13 - INFO - __main__ -   =======entity level========
08/18/2023 09:23:13 - INFO - __main__ -   
Epoch: 6, P: 0.925451, R: 0.908340, F: 0.916816, OOV: 0.797671
08/18/2023 09:23:13 - INFO - __main__ -   =======entity level========
08/18/2023 09:23:18 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:23:19 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:23:20 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:23:21 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:23:22 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:23:23 - INFO - __main__ -    self-train batch num in this step = 2
08/18/2023 09:23:24 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:23:25 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:23:26 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:23:28 - INFO - __main__ -   OOV: 0.788937
08/18/2023 09:23:28 - INFO - __main__ -   =======entity level========
08/18/2023 09:23:28 - INFO - __main__ -   
Epoch: 7, P: 0.913580, R: 0.902439, F: 0.907975, OOV: 0.788937
08/18/2023 09:23:28 - INFO - __main__ -   =======entity level========
08/18/2023 09:23:28 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:23:29 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:23:30 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:23:32 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:23:33 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:23:34 - INFO - __main__ -    self-train batch num in this step = 2
08/18/2023 09:23:35 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:23:36 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:23:37 - INFO - __main__ -    self-train batch num in this step = 1
08/18/2023 09:23:38 - INFO - __main__ -   OOV: 0.790393
08/18/2023 09:23:38 - INFO - __main__ -   =======entity level========
08/18/2023 09:23:38 - INFO - __main__ -   
Epoch: 8, P: 0.913199, R: 0.906373, F: 0.909773, OOV: 0.790393
08/18/2023 09:23:38 - INFO - __main__ -   =======entity level========
08/18/2023 09:23:39 - INFO - __main__ -    self-train batch num in this step = 1
